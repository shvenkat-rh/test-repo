name: AI Issue Analysis

on:
  issues:
    types: [opened]

jobs:
  analyze-issue:
    runs-on: ubuntu-latest
    
    permissions:
      issues: write
      contents: read
    
    steps:
      - name: Checkout current repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js for repomix
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Setup Python for AI analysis
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install repomix
        run: |
          npm install -g repomix
          echo "Repomix installed successfully"
          repomix --version
      
      - name: Generate repomix output for ansible-creator
        run: |
          echo "Reading configuration from triage.config.json..."
          REPO_URL=$(jq -r '.repository.url' triage.config.json)
          REPOMIX_OUTPUT=$(jq -r '.repomix.output_path' triage.config.json)
          echo "Repository URL: $REPO_URL"
          echo "Repomix output path: $REPOMIX_OUTPUT"
          
          echo "Running repomix on repository using remote..."
          repomix --remote "$REPO_URL" --output "$REPOMIX_OUTPUT"
          echo "Repomix output generated successfully"
          ls -la "$REPOMIX_OUTPUT"
      
      - name: Clone AI-Issue-Triage repository
        uses: actions/checkout@v4
        with:
          repository: shvenkat-rh/AI-Issue-Triage
          ref: main
          path: ai-triage
          fetch-depth: 1
      
      - name: Install Python dependencies for AI triage
        run: |
          cd ai-triage
          
          echo "Installing Python dependencies..."
          if pip install -r requirements.txt; then
            echo "Python dependencies installed successfully"
          else
            echo "ERROR: Failed to install Python dependencies"
            echo "Requirements file contents:"
            cat requirements.txt
            exit 1
          fi
          
          # Verify critical packages are installed
          python3 -c "import pytector; print('âœ“ pytector installed')" || echo "âš ï¸ pytector not available"
          python3 -c "import google.genai; print('âœ“ google-genai installed')" || echo "âš ï¸ google-genai not available"
      
      - name: Prepare issue content
        id: issue-content
        run: |
          # Extract issue title and body safely
          echo "Issue content prepared"

      - name: Check for prompt injection
        id: prompt-injection
        env:
          ISSUE_TITLE: ${{ github.event.issue.title }}
          ISSUE_DESCRIPTION: ${{ github.event.issue.body }}
        run: |
          cd ai-triage
          
          echo "Checking for prompt injection..."
          echo "ISSUE_TITLE: '$ISSUE_TITLE'"
          echo "ISSUE_DESCRIPTION: '$ISSUE_DESCRIPTION'"
          
          # Use the prompt injection detection from the AI-Issue-Triage repository
          if [ -f "utils/security/prompt_injection.py" ]; then
            echo "Using utils/security/prompt_injection.py for security check"
            
            # Run prompt injection detection using the clean CLI interface
            if python3 -m utils.security.prompt_injection "$ISSUE_TITLE" "$ISSUE_DESCRIPTION" > prompt_injection_result.json 2>prompt_injection_debug.log; then
              echo "Prompt injection detection completed successfully"
            else
              echo "WARNING: Prompt injection detection failed, running debug mode..."
              python3 -m utils.security.prompt_injection "$ISSUE_TITLE" "$ISSUE_DESCRIPTION" --debug > prompt_injection_result.json 2>&1 || {
                echo "Debug mode also failed, assuming safe input"
                echo '{"has_prompt_injection": false, "risk_level": "safe", "error": "detection_failed"}' > prompt_injection_result.json
              }
            fi
            
            echo "Script execution completed, checking results..."
            echo "Contents of prompt_injection_result.json:"
            cat prompt_injection_result.json || echo "No result file created"
            
            # Show debug log if it exists
            if [ -f prompt_injection_debug.log ] && [ -s prompt_injection_debug.log ]; then
              echo "Debug log contents:"
              cat prompt_injection_debug.log
            fi
            
            # Parse results with validation
            if [ -f prompt_injection_result.json ]; then
              # Validate JSON first
              if jq empty prompt_injection_result.json 2>/dev/null; then
                HAS_INJECTION=$(jq -r '.has_prompt_injection // false' prompt_injection_result.json)
                RISK_LEVEL=$(jq -r '.risk_level // "safe"' prompt_injection_result.json)
                echo "Parsed has_prompt_injection: $HAS_INJECTION"
                echo "Parsed risk_level: $RISK_LEVEL"
              else
                echo "ERROR: Invalid JSON in prompt_injection_result.json"
                echo "Raw content:"
                cat prompt_injection_result.json
                HAS_INJECTION="false"
                RISK_LEVEL="safe"
              fi
              
              echo "Setting GitHub outputs..."
              echo "has_prompt_injection=$HAS_INJECTION" >> $GITHUB_OUTPUT
              echo "risk_level=$RISK_LEVEL" >> $GITHUB_OUTPUT
              
              # Debug: Show what we're setting
              echo "DEBUG: GitHub output file contents:"
              cat $GITHUB_OUTPUT | grep -E "(has_prompt_injection|risk_level)" || echo "No matching outputs found"
              
              if [ "$HAS_INJECTION" = "true" ]; then
                echo "SECURITY ALERT: Prompt injection detected! Risk Level: $RISK_LEVEL"
                echo "This should trigger the warning step!"
              else
                echo "No prompt injection detected"
              fi
            else
              echo "No result file found, assuming no injection"
              echo "has_prompt_injection=false" >> $GITHUB_OUTPUT
              echo "risk_level=safe" >> $GITHUB_OUTPUT
            fi
          else
            echo "utils/security/prompt_injection.py not found, skipping security check"
            echo "has_prompt_injection=false" >> $GITHUB_OUTPUT
            echo "risk_level=safe" >> $GITHUB_OUTPUT
          fi

      - name: Post prompt injection warning
        if: steps.prompt-injection.outputs.has_prompt_injection == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const riskLevel = '${{ steps.prompt-injection.outputs.risk_level }}';
            const riskEmoji = {
              'critical': 'ðŸš¨',
              'high': 'âš ï¸',
              'medium': 'âš¡',
              'low': 'â„¹ï¸'
            };
            
            const isHighRisk = ['critical', 'high'].includes(riskLevel);
            
            let comment = (riskEmoji[riskLevel] || 'âš ï¸') + ' **Security Alert: Potential Prompt Injection Detected**\n\n' +
              '**Risk Level:** ' + riskLevel.toUpperCase() + '\n\n';
            
            if (isHighRisk) {
              comment += 'This issue contains content that appears to be a significant prompt injection attempt. For security reasons, this issue will not be processed by the AI analysis system.\n\n' +
                '**What is prompt injection?**\n' +
                'Prompt injection is a type of attack where malicious instructions are embedded in user input to manipulate AI systems into performing unintended actions.\n\n' +
                '**Next Steps:**\n' +
                '- This issue will remain open but will not receive AI analysis\n' +
                '- Please review the issue content and remove any suspicious instructions\n' +
                '- If this is a legitimate issue, please rephrase it using clear, direct language\n' +
                '- Contact the repository maintainers if you believe this detection is incorrect\n\n';
            } else {
              comment += 'This issue contains content that may contain prompt injection patterns, but the risk level is considered manageable. The issue will be processed with additional security measures.\n\n' +
                '**What was detected?**\n' +
                'The content contains patterns that could potentially be used for prompt injection, but the confidence level is low enough to allow processing.\n\n' +
                '**Next Steps:**\n' +
                '- This issue will continue to receive AI analysis with enhanced security filtering\n' +
                '- If you intended to include instructions for the AI, please use clear, direct language\n' +
                '- Contact the repository maintainers if you have concerns about this detection\n\n';
            }
            
            comment += '---\n*This security check is performed automatically to protect the AI analysis system.*';
            
            // Post the comment
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
            
            // Add appropriate security labels
            const labels = ['security-alert'];
            if (isHighRisk) {
              labels.push('prompt-injection-blocked');
            } else {
              labels.push('prompt-injection-warning');
            }
            
            await github.rest.issues.addLabels({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: labels
            });
            
            console.log(`Prompt injection ${isHighRisk ? 'blocking' : 'warning'} posted with security labels`);

      # Only end workflow for HIGH and CRITICAL risk injections
      - name: End workflow for high-risk prompt injection
        if: steps.prompt-injection.outputs.has_prompt_injection == 'true' && (steps.prompt-injection.outputs.risk_level == 'high' || steps.prompt-injection.outputs.risk_level == 'critical')
        run: |
          echo "Workflow terminated due to HIGH/CRITICAL risk prompt injection detection"
          echo "Risk level: ${{ steps.prompt-injection.outputs.risk_level }}"
          echo "Issue has been flagged with security alert - no further processing will occur"
          exit 0

      # Set a flag for whether to continue processing (safe OR low/medium risk)
      - name: Determine if processing should continue
        id: should-continue
        run: |
          if [ "${{ steps.prompt-injection.outputs.has_prompt_injection }}" = "true" ]; then
            RISK_LEVEL="${{ steps.prompt-injection.outputs.risk_level }}"
            if [ "$RISK_LEVEL" = "high" ] || [ "$RISK_LEVEL" = "critical" ]; then
              echo "continue_processing=false" >> $GITHUB_OUTPUT
              echo "Processing blocked due to high-risk prompt injection"
            else
              echo "continue_processing=true" >> $GITHUB_OUTPUT
              echo "Processing continues with low/medium risk injection warning"
            fi
          else
            echo "continue_processing=true" >> $GITHUB_OUTPUT
            echo "Processing continues - no prompt injection detected"
          fi

      - name: Fetch existing issues for duplicate check
        id: fetch-issues
        if: steps.should-continue.outputs.continue_processing == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Get all open issues (excluding the current one)
            const { data: issues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              per_page: 100
            });
            
            // Filter out pull requests and the current issue
            const actualIssues = issues.filter(issue => 
              !issue.pull_request && 
              issue.number !== context.issue.number
            );
            
            // Create issues data file for duplicate_cli
            const issuesData = actualIssues.map(issue => ({
              number: issue.number,
              title: issue.title,
              body: issue.body || '',
              url: issue.html_url
            }));
            
            fs.writeFileSync('existing_issues.json', JSON.stringify(issuesData, null, 2));
            console.log(`Fetched ${actualIssues.length} existing issues for duplicate checking`);

      - name: Check for duplicate issues
        id: duplicate-check
        if: steps.should-continue.outputs.continue_processing == 'true'
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          ISSUE_TITLE: ${{ github.event.issue.title }}
          ISSUE_DESCRIPTION: ${{ github.event.issue.body }}
        run: |
          cd ai-triage
          
          # Read repomix output path from config
          REPOMIX_OUTPUT=$(jq -r '.repomix.output_path' ../triage.config.json)
          
          # Copy the repomix output and issues data to the AI triage directory
          cp "../$REPOMIX_OUTPUT" .
          cp ../existing_issues.json .
          
          # Run duplicate check first
          echo "Checking for duplicate issues..."
          echo "Current directory: $(pwd)"
          echo "Files in directory: $(ls -la)"
          echo "Checking if cli/duplicate_check.py exists: $(ls -la cli/duplicate_check.py 2>/dev/null || echo 'NOT FOUND')"
          
          # Check if cli/duplicate_check.py exists and is executable
          if [ ! -f "cli/duplicate_check.py" ]; then
            echo "ERROR: cli/duplicate_check.py not found in ai-triage directory"
            echo "Available Python files:"
            find . -name "*.py" -type f
            exit 1
          fi
          
          # Run duplicate check with error handling
          set +e  # Don't exit on error temporarily
          python -m cli.duplicate_check \
            --title "$ISSUE_TITLE" \
            --description "$ISSUE_DESCRIPTION" \
            --issues existing_issues.json \
            --output json > duplicate_result.json 2>&1
          
          DUPLICATE_EXIT_CODE=$?
          set -e  # Re-enable exit on error
          
          if [ $DUPLICATE_EXIT_CODE -ne 0 ]; then
            echo "ERROR: cli/duplicate_check.py failed with exit code $DUPLICATE_EXIT_CODE"
            echo "Output from duplicate_result.json:"
            cat duplicate_result.json 2>/dev/null || echo "No output file created"
            
            # Create a fallback result indicating no duplicate found
            echo '{"is_duplicate": false, "error": "cli/duplicate_check.py failed"}' > duplicate_result.json
            echo "No duplicate detected (cli/duplicate_check.py failed)" > duplicate_result.txt
          else
            # Also generate text format for duplicate check
            python -m cli.duplicate_check \
              --title "$ISSUE_TITLE" \
              --description "$ISSUE_DESCRIPTION" \
              --issues existing_issues.json \
              --output text > duplicate_result.txt
          fi
          
          echo "Duplicate check completed"
          
          # Check if duplicate was found
          if [ -f duplicate_result.json ]; then
            IS_DUPLICATE=$(jq -r '.is_duplicate // false' duplicate_result.json)
            echo "is_duplicate=$IS_DUPLICATE" >> $GITHUB_OUTPUT
            
            if [ "$IS_DUPLICATE" = "true" ]; then
              DUPLICATE_ISSUE_URL=$(jq -r '.duplicate_issue_url // ""' duplicate_result.json)
              DUPLICATE_ISSUE_NUMBER=$(jq -r '.duplicate_issue_number // ""' duplicate_result.json)
              echo "duplicate_issue_url=$DUPLICATE_ISSUE_URL" >> $GITHUB_OUTPUT
              echo "duplicate_issue_number=$DUPLICATE_ISSUE_NUMBER" >> $GITHUB_OUTPUT
              echo "Duplicate issue found: $DUPLICATE_ISSUE_URL"
            fi
          fi

      - name: Run AI issue analysis
        id: analysis
        if: steps.duplicate-check.outputs.is_duplicate != 'true' && steps.should-continue.outputs.continue_processing == 'true'
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          ISSUE_TITLE: ${{ github.event.issue.title }}
          ISSUE_DESCRIPTION: ${{ github.event.issue.body }}
        run: |
          cd ai-triage
          
          # Read configuration
          REPOMIX_OUTPUT=$(jq -r '.repomix.output_path' ../triage.config.json)
          CUSTOM_PROMPT=$(jq -r '.analysis.custom_prompt_path' ../triage.config.json)
          
          # Build CLI arguments
          CLI_ARGS="--title \"$ISSUE_TITLE\" --description \"$ISSUE_DESCRIPTION\" --source-path \"$REPOMIX_OUTPUT\""
          
          # Add custom prompt if specified
          if [ -n "$CUSTOM_PROMPT" ] && [ "$CUSTOM_PROMPT" != "null" ] && [ "$CUSTOM_PROMPT" != "" ]; then
            if [ -f "../$CUSTOM_PROMPT" ]; then
              CLI_ARGS="$CLI_ARGS --custom-prompt \"../$CUSTOM_PROMPT\""
              echo "Using custom prompt: $CUSTOM_PROMPT"
            else
              echo "Warning: Custom prompt file not found: $CUSTOM_PROMPT, using default prompt"
            fi
          fi
          
          # Run the CLI analysis using environment variables
          echo "Running AI analysis..."
          eval "python -m cli.analyze $CLI_ARGS --format json --output analysis_result.json --quiet"
          
          echo "Analysis completed successfully"
          
          # Also generate a text format for the comment
          eval "python -m cli.analyze $CLI_ARGS --format text --output analysis_result.txt --quiet"
          
          echo "Text analysis generated"
      
      - name: Parse Analysis Results
        id: parse
        if: steps.duplicate-check.outputs.is_duplicate != 'true' && steps.should-continue.outputs.continue_processing == 'true'
        run: |
          cd ai-triage
          
          # Extract key information from the analysis
          ISSUE_TYPE=$(jq -r '.issue_type' analysis_result.json)
          SEVERITY=$(jq -r '.severity' analysis_result.json)
          CONFIDENCE=$(jq -r '.confidence_score' analysis_result.json)
          SUMMARY=$(jq -r '.analysis_summary' analysis_result.json)
          
          echo "issue_type=$ISSUE_TYPE" >> $GITHUB_OUTPUT
          echo "severity=$SEVERITY" >> $GITHUB_OUTPUT
          echo "confidence=$CONFIDENCE" >> $GITHUB_OUTPUT
          echo "summary<<EOF" >> $GITHUB_OUTPUT
          echo "$SUMMARY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
      
      - name: Post duplicate issue comment
        if: steps.duplicate-check.outputs.is_duplicate == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Read the duplicate check result
            let duplicateText;
            try {
              duplicateText = fs.readFileSync('ai-triage/duplicate_result.txt', 'utf8');
            } catch (error) {
              console.error('Error reading duplicate result file:', error);
              duplicateText = 'This issue appears to be a duplicate, but failed to read detailed analysis.';
            }
            
            const duplicateUrl = '${{ steps.duplicate-check.outputs.duplicate_issue_url }}';
            const duplicateNumber = '${{ steps.duplicate-check.outputs.duplicate_issue_number }}';
            
            let comment = '**Duplicate Issue Detected**\n\n';
            comment += duplicateText + '\n\n';
            
            if (duplicateUrl) {
              comment += `**Related Issue**: ${duplicateUrl}\n`;
            } else if (duplicateNumber) {
              comment += `**Related Issue**: #${duplicateNumber}\n`;
            }
            
            comment += '\n---\n*This analysis was performed automatically by AI.*';
            
            // Post the comment
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
            
            console.log('Duplicate issue comment posted successfully');

      - name: Post analysis as issue comment
        if: steps.duplicate-check.outputs.is_duplicate != 'true' && steps.should-continue.outputs.continue_processing == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Read the analysis result
            let analysisText;
            try {
              analysisText = fs.readFileSync('ai-triage/analysis_result.txt', 'utf8');
            } catch (error) {
              console.error('Error reading analysis file:', error);
              analysisText = 'Failed to read analysis results.';
            }
            
            // Use plain text analysis result without formatting
            const comment = analysisText;
            
            // Post the comment
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
            
            console.log('Analysis comment posted successfully');
      
      - name: Add Labels Based on Analysis
        uses: actions/github-script@v7
        with:
          script: |
            const isDuplicate = '${{ steps.duplicate-check.outputs.is_duplicate }}' === 'true';
            const issueType = '${{ steps.parse.outputs.issue_type }}';
            const severity = '${{ steps.parse.outputs.severity }}';
            
            const labels = [];
            
            if (isDuplicate) {
              // Add duplicate-specific labels
              labels.push('gemini-analyzed');
              labels.push('duplicate');
            } else {
              // Add analysis label
              labels.push('gemini-analyzed');
              
              // Add type label if available
              if (issueType && issueType !== 'null' && issueType !== '') {
                labels.push(`type:${issueType.toLowerCase()}`);
              }
              
              // Add severity label if available
              if (severity && severity !== 'null' && severity !== '') {
                labels.push(`severity:${severity.toLowerCase()}`);
              }
            }
            
            if (labels.length > 0) {
              await github.rest.issues.addLabels({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                labels: labels
              });
              
              console.log(`Added labels: ${labels.join(', ')}`);
            }
      
      - name: Upload analysis artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: issue-analysis-${{ github.event.issue.number }}
          path: |
            existing_issues.json
            ai-triage/duplicate_result.json
            ai-triage/duplicate_result.txt
            ai-triage/analysis_result.json
            ai-triage/analysis_result.txt
            ai-triage/prompt_injection_result.json
            ai-triage/prompt_injection_debug.log
            repomix-output.txt
            triage.config.json
          retention-days: 30

